{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "demo5-modified.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "8e6bd1230bbd48dd91ace4480259441d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_f9be3c2618804d0da53b3a4c1e3c7771",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_0b37c32b83ee4763946f48298e477799",
       "IPY_MODEL_fc8a5c2c86d649748726414726a57785",
       "IPY_MODEL_af58f5bd665c430ba792749f2ead00cc"
      ]
     }
    },
    "f9be3c2618804d0da53b3a4c1e3c7771": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "0b37c32b83ee4763946f48298e477799": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_2f4fd22b39524dd4b0881c0825536b40",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": "100%",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_af3d246d8e064a1e9263f9bdd643e804"
     }
    },
    "fc8a5c2c86d649748726414726a57785": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_ecddbc061422425e81c4371df7ab2968",
      "_dom_classes": [],
      "description": "",
      "_model_name": "FloatProgressModel",
      "bar_style": "success",
      "max": 87319819,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 87319819,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_971291ee22064d44bfc12e1265bc20ae"
     }
    },
    "af58f5bd665c430ba792749f2ead00cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_1559532c2fe640af8f91048b595c26e8",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 83.3M/83.3M [00:01&lt;00:00, 102MB/s]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_f16c9212a36a4fd387d65871c499062f"
     }
    },
    "2f4fd22b39524dd4b0881c0825536b40": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "af3d246d8e064a1e9263f9bdd643e804": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "ecddbc061422425e81c4371df7ab2968": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "971291ee22064d44bfc12e1265bc20ae": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "1559532c2fe640af8f91048b595c26e8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "f16c9212a36a4fd387d65871c499062f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fc9wyyGloQwL"
   },
   "source": [
    "# Finetuning and Understanding ResNet\n",
    "\n",
    "Modern deep convnets tend to have tens (if not hundreds) of layers, with millions (if not tens of millions) of trainable parameters. More often than not several of these layers have skipped connections; the *ResNet* family of networks are an example. \n",
    "\n",
    "The flip side of having such deep network architectures is that to properly learn such networks, one requires *massive* amounts of training data. In most applications, access to such massive datasets simply isn't available; gathering and curating a dataset with a few hundred/thousand examples itself can be a challenge.\n",
    "\n",
    "What should one do in the ``small data'' setting? A possible solution:\n",
    "* start with a deep network architecture initialized with *pre-trained* weights, and\n",
    "* *fine-tune* the network weights on the (small) training dataset.\n",
    "\n",
    "In this demo we will see how to train a simple cat-vs-dog classifier using a very small training dataset of 60 images. The dataset is provided [here](https://github.com/chinmayhegde/dl-demos/blob/main/data.zip). You can unzip and save the dataset anywhere you like; I've saved it to my Google drive folder: `content/`. (You can easily find out about the path doing: copy the path location from the table of contents on the left side by clicking the dot menu on RHS of some folder -> copy path.)\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "! pip install d2l==0.17.2\n",
    "# you might need to restart your runtime after this installation.\n",
    "# just follow the steps that pops up at the end of downloads..\n",
    "# we need this for running Dive into Deep Learning scripts (towards the end of the notebook)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KEvZwy_Qxusc",
    "outputId": "76223bcf-e6ed-4202-9e44-498a82cf94f8"
   },
   "execution_count": 16,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: d2l==0.17.2 in /usr/local/lib/python3.7/dist-packages (0.17.2)\n",
      "Requirement already satisfied: numpy==1.18.5 in /usr/local/lib/python3.7/dist-packages (from d2l==0.17.2) (1.18.5)\n",
      "Requirement already satisfied: pandas==1.2.2 in /usr/local/lib/python3.7/dist-packages (from d2l==0.17.2) (1.2.2)\n",
      "Requirement already satisfied: matplotlib==3.3.3 in /usr/local/lib/python3.7/dist-packages (from d2l==0.17.2) (3.3.3)\n",
      "Requirement already satisfied: requests==2.25.1 in /usr/local/lib/python3.7/dist-packages (from d2l==0.17.2) (2.25.1)\n",
      "Requirement already satisfied: jupyter==1.0.0 in /usr/local/lib/python3.7/dist-packages (from d2l==0.17.2) (1.0.0)\n",
      "Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from jupyter==1.0.0->d2l==0.17.2) (4.10.1)\n",
      "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from jupyter==1.0.0->d2l==0.17.2) (5.6.1)\n",
      "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from jupyter==1.0.0->d2l==0.17.2) (7.6.5)\n",
      "Requirement already satisfied: notebook in /usr/local/lib/python3.7/dist-packages (from jupyter==1.0.0->d2l==0.17.2) (5.3.1)\n",
      "Requirement already satisfied: qtconsole in /usr/local/lib/python3.7/dist-packages (from jupyter==1.0.0->d2l==0.17.2) (5.2.2)\n",
      "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.7/dist-packages (from jupyter==1.0.0->d2l==0.17.2) (5.2.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.3->d2l==0.17.2) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.3->d2l==0.17.2) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.3->d2l==0.17.2) (7.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.3->d2l==0.17.2) (2.8.2)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.3->d2l==0.17.2) (3.0.7)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.2.2->d2l==0.17.2) (2018.9)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests==2.25.1->d2l==0.17.2) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests==2.25.1->d2l==0.17.2) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests==2.25.1->d2l==0.17.2) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests==2.25.1->d2l==0.17.2) (1.24.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib==3.3.3->d2l==0.17.2) (1.15.0)\n",
      "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter==1.0.0->d2l==0.17.2) (5.3.5)\n",
      "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter==1.0.0->d2l==0.17.2) (5.1.1)\n",
      "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter==1.0.0->d2l==0.17.2) (5.1.1)\n",
      "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter==1.0.0->d2l==0.17.2) (5.5.0)\n",
      "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter==1.0.0->d2l==0.17.2) (0.8.1)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter==1.0.0->d2l==0.17.2) (2.6.1)\n",
      "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter==1.0.0->d2l==0.17.2) (1.0.18)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter==1.0.0->d2l==0.17.2) (0.7.5)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter==1.0.0->d2l==0.17.2) (4.4.2)\n",
      "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter==1.0.0->d2l==0.17.2) (57.4.0)\n",
      "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter==1.0.0->d2l==0.17.2) (4.8.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipykernel->jupyter==1.0.0->d2l==0.17.2) (0.2.5)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter==1.0.0->d2l==0.17.2) (0.2.0)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter==1.0.0->d2l==0.17.2) (3.5.2)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter==1.0.0->d2l==0.17.2) (1.0.2)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter==1.0.0->d2l==0.17.2) (5.1.3)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->d2l==0.17.2) (4.3.3)\n",
      "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->d2l==0.17.2) (4.9.2)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->d2l==0.17.2) (0.18.1)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->d2l==0.17.2) (4.11.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->d2l==0.17.2) (21.4.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->d2l==0.17.2) (3.10.0.2)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->d2l==0.17.2) (5.4.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->d2l==0.17.2) (3.7.0)\n",
      "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter==1.0.0->d2l==0.17.2) (0.13.1)\n",
      "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter==1.0.0->d2l==0.17.2) (1.8.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter==1.0.0->d2l==0.17.2) (2.11.3)\n",
      "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel->jupyter==1.0.0->d2l==0.17.2) (22.3.0)\n",
      "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook->jupyter==1.0.0->d2l==0.17.2) (0.7.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook->jupyter==1.0.0->d2l==0.17.2) (2.0.1)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter==1.0.0->d2l==0.17.2) (0.4)\n",
      "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter==1.0.0->d2l==0.17.2) (4.1.0)\n",
      "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter==1.0.0->d2l==0.17.2) (0.7.1)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter==1.0.0->d2l==0.17.2) (0.8.4)\n",
      "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter==1.0.0->d2l==0.17.2) (0.5.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter==1.0.0->d2l==0.17.2) (1.5.0)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter==1.0.0->d2l==0.17.2) (0.5.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter==1.0.0->d2l==0.17.2) (21.3)\n",
      "Requirement already satisfied: qtpy in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter==1.0.0->d2l==0.17.2) (2.0.1)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "bGT3H4DjoO9n"
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "! pwd # printing working directory"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3jppOEsst5fj",
    "outputId": "d347c9b4-9129-4c19-d5e2-7494a88a4fcd"
   },
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/content\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "! unzip data.zip # unzips"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7I8qFappY_O4",
    "outputId": "3fba0eff-bd4d-4c2b-f7df-64d7767c1e92"
   },
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Archive:  data.zip\n",
      "replace data/train/cat/11.jpeg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "qNHnEAckpqps"
   },
   "source": [
    "# data transforms\n",
    "dset_transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])])\n",
    "\n",
    "\n",
    "# Use the image folder function to create datasets\n",
    "dsets = {x: datasets.ImageFolder(f\"/content/data/{x}\", dset_transform)\n",
    "         for x in ['train', 'val']}\n",
    "\n",
    "# create data loader\n",
    "dataloaders = {x: torch.utils.data.DataLoader(dsets[x], batch_size=16,\n",
    "                                              shuffle=(x == \"train\"))\n",
    "               for x in ['train', 'val']}\n"
   ],
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iYSEZtTDJUYV"
   },
   "source": [
    "# Loading a pre-trained ResNet model\n",
    "\n",
    "Let's load a ResNet34 model from `torchvision` and examine it."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "tOYRfm1pBcoM",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87,
     "referenced_widgets": [
      "8e6bd1230bbd48dd91ace4480259441d",
      "f9be3c2618804d0da53b3a4c1e3c7771",
      "0b37c32b83ee4763946f48298e477799",
      "fc8a5c2c86d649748726414726a57785",
      "af58f5bd665c430ba792749f2ead00cc",
      "2f4fd22b39524dd4b0881c0825536b40",
      "af3d246d8e064a1e9263f9bdd643e804",
      "ecddbc061422425e81c4371df7ab2968",
      "971291ee22064d44bfc12e1265bc20ae",
      "1559532c2fe640af8f91048b595c26e8",
      "f16c9212a36a4fd387d65871c499062f"
     ]
    },
    "outputId": "686c6dfd-86df-444f-8477-8b87594a5021"
   },
   "source": [
    "# intialize model\n",
    "model = models.resnet34(pretrained=True)"
   ],
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e6bd1230bbd48dd91ace4480259441d",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "  0%|          | 0.00/83.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mVgCL8ZTtvTt",
    "outputId": "197cc8d8-b77d-4423-cfbd-73266eecc73c"
   },
   "source": [
    "print(model)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (4): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (5): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EfWGLTlJLxzI"
   },
   "source": [
    "Hmm, lots of layers. Each `BasicBlock` is two or three conv layers with a skipped connection, with batch-norm layers thrown in for good measure. Several such residual blocks are pieced together, and in the end there is a dense layer with 1000 output neurons. This model has been trained on the well-known *ImageNet* dataset (which has over a million images with 1000 classes). As an aside, let's examine the number of trainable parameters in the model."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jl9m-Z4EDFFW",
    "outputId": "1ebf4eef-85cb-4646-c6a1-aa07e4ab4acd"
   },
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    # torch.numel() returns number of elements in a tensor\n",
    "\n",
    "print(count_parameters(model))"
   ],
   "execution_count": 7,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "21797672\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FdzbKTClM_Qv"
   },
   "source": [
    "Let us finetune this model for our cat-vs-dog classification problem. Since this is a binary classifier we will redefine the output (linear) layer to have 2 outputs."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qkjny7j5BDRS",
    "outputId": "02621fa7-a709-453c-ad54-d065a04b9c13"
   },
   "source": [
    "num_ftrs = model.fc.in_features\n",
    "print(num_ftrs)\n",
    "# this is also listed above in the last layer of ResNet info printout"
   ],
   "execution_count": 8,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "512\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "nhnOEfZoDQS6"
   },
   "source": [
    "model.fc = nn.Linear(num_ftrs, 2) # redefine the last fc layer according to our problem setup"
   ],
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jv86CyS3DVe8",
    "outputId": "c97cb790-9247-4544-81c1-b2aee746db02"
   },
   "source": [
    "print(model)"
   ],
   "execution_count": 10,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (4): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (5): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TIDpqRLJOMaJ"
   },
   "source": [
    "Observe now that the basic ResNet34 backbone remains the same; only the output layer has changed. In fact, all of the weights (except the output layer) also have been retained.  \n",
    "\n",
    "Let's do a quick model evaluation to check if there are any errors thrown during prediction."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bq72K2tuDn3h",
    "outputId": "a80ef1c8-d44f-4300-ba54-80ba39e811ab"
   },
   "source": [
    "model.eval()\n",
    "corrects = 0\n",
    "for batch_idx, (inputs,labels) in enumerate(dataloaders['val'], 1):\n",
    "  with torch.set_grad_enabled(False):\n",
    "    outputs = model(inputs)\n",
    "    #print(outputs.shape)\n",
    "    _, preds = torch.max(outputs,1)\n",
    "    \n",
    "  corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "print(corrects.float() / len(dataloaders['val'].dataset))"
   ],
   "execution_count": 12,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor(0.2917)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LI3eN9vcPEHb"
   },
   "source": [
    "As we can see, we get a low accuracy on the validation set -- which is exactly what we would expect since the weights of the output layer are random in the last layer that we have just defined. \n",
    "\n",
    "We are now ready to start fine-tuning! The rest of the code below is boilerplate training; we see below that only a few epochs are enough to tune the weights to our training dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "UZ8n_358A6aY"
   },
   "source": [
    "# define loss function, optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "save_loss = {'train':[], 'val':[]}\n",
    "save_acc = {'train':[], 'val':[]}"
   ],
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wJHYjaYtrNHm",
    "outputId": "e6c46c13-e93b-400d-8ef5-009154c43da8"
   },
   "source": [
    "for epoch in range(5):\n",
    "\n",
    "    # Each epoch has a training and validation phase\n",
    "    for phase in ['train', 'val']:\n",
    "        if phase == 'train':\n",
    "            model.train()  # Set model to training mode\n",
    "        else:\n",
    "            model.eval()   # Set model to evaluate mode\n",
    "\n",
    "        current_loss = 0.0\n",
    "        current_corrects = 0\n",
    "\n",
    "        for batch_idx, (inputs, labels) in enumerate(dataloaders[phase], 1):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Time to carry out the forward training poss\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # backward + optimize only if in training phase\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "            # We want variables to hold the loss/acc statistics\n",
    "            current_loss += loss.item() * inputs.size(0)\n",
    "            current_corrects += torch.sum(preds == labels.data)\n",
    "        # saving variable for plottin\n",
    "        save_loss[phase] += [current_loss / len(dataloaders[phase].dataset)]\n",
    "        save_acc[phase] += [current_corrects.float() / len(dataloaders[phase].dataset)]\n",
    "\n",
    "        # pretty print\n",
    "        print(f\"Epoch:{epoch} -- Phase:{phase} -- Loss:{save_loss[phase][-1]:.2f} -- Acc:{save_acc[phase][-1]*100:.2f}\")\n"
   ],
   "execution_count": 15,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch:0 -- Phase:train -- Loss:0.71 -- Acc:56.67\n",
      "Epoch:0 -- Phase:val -- Loss:0.53 -- Acc:79.17\n",
      "Epoch:1 -- Phase:train -- Loss:0.39 -- Acc:91.67\n",
      "Epoch:1 -- Phase:val -- Loss:0.24 -- Acc:100.00\n",
      "Epoch:2 -- Phase:train -- Loss:0.17 -- Acc:98.33\n",
      "Epoch:2 -- Phase:val -- Loss:0.11 -- Acc:100.00\n",
      "Epoch:3 -- Phase:train -- Loss:0.11 -- Acc:100.00\n",
      "Epoch:3 -- Phase:val -- Loss:0.07 -- Acc:100.00\n",
      "Epoch:4 -- Phase:train -- Loss:0.06 -- Acc:100.00\n",
      "Epoch:4 -- Phase:val -- Loss:0.04 -- Acc:100.00\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "id": "JGgbCwdTuy1h",
    "outputId": "1b5c7afd-b397-4336-d3f4-07958b8c2b9d"
   },
   "source": [
    "plt.plot(save_acc['train'])\n",
    "plt.plot(save_acc['val'])\n",
    "plt.legend([\"train\", \"val\"])\n",
    "plt.title(\"Accuracy\")\n"
   ],
   "execution_count": 16,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Accuracy')"
      ]
     },
     "metadata": {},
     "execution_count": 16
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h1__s46hPeUg"
   },
   "source": [
    "There we go! That took only 4 epochs of finetuning.\n",
    "\n",
    "This was a very small dataset (of only 60 training images) so it is not that surprising that we were able to fit the data so easily. Try training your own classifier with a slightly larger set of data points, and see if you can get similar results."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's now into analyse ResNet architecture in more detail. The rest of the notebook is adopted from [Dive into Deep Learning](https://https://d2l.ai/chapter_convolutional-modern/resnet.html)."
   ],
   "metadata": {
    "id": "LT1SuWIvx257"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "ResNet's architecture is similar to VGG's: full  of 3×3  convolutional layers. The residual block has two  3×3  convolutional layers with the same number of output channels. Each convolutional layer is followed by a batch normalization layer and a ReLU activation function (see the below code to confirm this). Then, we skip these two convolution operations and add the input directly before the final ReLU activation function (again see the code below!). This kind of design requires that the output of the two convolutional layers has to be of the same shape as the input, so that they can be added together (otherwise, simply dimensions do not match..). If we want to change the number of channels, we need to introduce an additional  1×1  convolutional layer to transform the input into the desired shape for the addition operation (see `self.conv3` in the code below). Let's check the code."
   ],
   "metadata": {
    "id": "LGM2ZIzey-sj"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from d2l import torch as d2l\n",
    "\n",
    "\n",
    "class Residual(nn.Module):  \n",
    "    \"\"\"The Residual block of ResNet.\"\"\"\n",
    "    def __init__(self, input_channels, num_channels,\n",
    "                 use_1x1conv=False, strides=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(input_channels, num_channels,\n",
    "                               kernel_size=3, padding=1, stride=strides)\n",
    "        self.conv2 = nn.Conv2d(num_channels, num_channels,\n",
    "                               kernel_size=3, padding=1)\n",
    "        if use_1x1conv:\n",
    "            self.conv3 = nn.Conv2d(input_channels, num_channels,\n",
    "                                   kernel_size=1, stride=strides)\n",
    "        else:\n",
    "            self.conv3 = None\n",
    "        self.bn1 = nn.BatchNorm2d(num_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(num_channels)\n",
    "\n",
    "    def forward(self, X):\n",
    "        Y = F.relu(self.bn1(self.conv1(X)))\n",
    "        Y = self.bn2(self.conv2(Y))\n",
    "        if self.conv3:\n",
    "            X = self.conv3(X)\n",
    "        Y += X\n",
    "        return F.relu(Y)"
   ],
   "metadata": {
    "id": "Sa3_q6yLyde1"
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note that instead of `F.relu()` you could have also used `nn.RelU()` in the code above. Check the explanation [here](https://discuss.pytorch.org/t/whats-the-difference-between-nn-relu-vs-f-relu/27599).\n",
    "\n",
    "(Think about why you can do this -- are you learning anything with respect to ReLU in backpropogation?)"
   ],
   "metadata": {
    "id": "wNVpH9NQz-IN"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Following is the situation where the input and output are of the same dimension. (Why?)\n",
    "\n"
   ],
   "metadata": {
    "id": "tHbNZ-Fu0lqx"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "blk = Residual(3,3)\n",
    "X = torch.rand(4, 3, 6, 6)\n",
    "Y = blk(X)\n",
    "Y.shape\n",
    "# https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html \n",
    "# here is the documentation about input/output shapes of nn.Conv2d()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IG9-m6K20Mad",
    "outputId": "3f322bc3-bd56-4524-e199-422de9f812bf"
   },
   "execution_count": 14,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 6, 6])"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can easily decrease the output's height and width while increasing the number of output channels as follows."
   ],
   "metadata": {
    "id": "r7lkulxE1xs3"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "blk = Residual(3, 6, use_1x1conv=True, strides=2)\n",
    "blk(X).shape\n",
    "# since we are changing the number of channels from 3 to 6, \n",
    "# we have use_1x1conv=True"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1AQnl1Xy1vx5",
    "outputId": "a4fced6e-78bc-4f7d-ffd7-dae47853832b"
   },
   "execution_count": 15,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([4, 6, 3, 3])"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "You can follow the rest of the Dive into Deep Learning notebook from [here](https://d2l.ai/chapter_convolutional-modern/resnet.html)."
   ],
   "metadata": {
    "id": "1iADeGrM3nqA"
   }
  }
 ]
}