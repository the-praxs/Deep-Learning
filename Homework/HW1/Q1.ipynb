{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Q1 Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import torch\n",
    "# Setting up device as CUDA if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creating class Net for easy use"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "class Net:\n",
    "  def __init__(self, x):\n",
    "    # Input\n",
    "    self.x = x\n",
    "\n",
    "    # Initializing first set of weights and bias as Torch tensors\n",
    "    self.Wh = torch.tensor([[2, 4], [3, -5]], dtype=torch.int32)\n",
    "    self.bh = torch.tensor([[-2], [1]], dtype=torch.int32)\n",
    "\n",
    "    # Initializing second set of weights and bias as Torch tensors\n",
    "    self.Wo = torch.tensor([4, 6], dtype=torch.int32)\n",
    "    self.bo = torch.tensor([-3.5], dtype=torch.float32)\n",
    "\n",
    "    # Initializing all computations as 0\n",
    "    self.zh = 0\n",
    "    self.uh = 0\n",
    "    self.zo = 0\n",
    "    self.y = 1\n",
    "\n",
    "  def sigmoid(self, x):\n",
    "    return 1 / (1 + torch.exp(-x))\n",
    "\n",
    "  def ReLU(self, x):\n",
    "    return torch.maximum(torch.zeros_like(x), x)\n",
    "    \n",
    "  def cross_entropy_loss(self, yHat, y):\n",
    "    return -torch.sum(y * torch.log(yHat))\n",
    "  \n",
    "  def forward_pass(self):\n",
    "    # Linear Map 1\n",
    "    self.zh = torch.matmul(self.Wh, self.x) + self.bh\n",
    "    \n",
    "    # Activation ReLU\n",
    "    self.uh = self.ReLU(self.zh)\n",
    "\n",
    "    # Linear Map 2\n",
    "    self.zo = torch.matmul(self.Wo, self.uh) + self.bo\n",
    "    # Activation Sigmoid\n",
    "    yHat = self.sigmoid(self.zo)\n",
    "\n",
    "    # Calculate Cross-Entropy Loss\n",
    "    loss = self.cross_entropy_loss(yHat, self.y)\n",
    "\n",
    "    return loss, yHat\n",
    "\n",
    "  def backward_pass(self, yHat):\n",
    "    dLoss = -(self.y/yHat) + ((1 - self.y) / (1 - yHat))\n",
    "    dyHat = self.sigmoid(self.zo) * (1 - self.sigmoid(self.zo))\n",
    "    dzo_Wo = self.uh\n",
    "    dzo_bo = 1\n",
    "    dzo_uh = self.Wo\n",
    "    duh = torch.tensor([[1 if self.zh[0]>=0 else 0], [1 if self.zh[1]>=0 else 0]], dtype=torch.int32)\n",
    "    dzh_Wh = self.x\n",
    "    dzh_bh = 1\n",
    "\n",
    "    '''\n",
    "    # FOR DEBUG PURPOSES\n",
    "    print(dLoss, dLoss.shape, '\\n')\n",
    "    print(dyHat, dyHat.shape, '\\n')\n",
    "    print(dzo_Wo, dzo_Wo.shape, '\\n')\n",
    "    print(dzo_bo, '\\n')\n",
    "    print(dzo_uh, dzo_uh.shape, '\\n')\n",
    "    print(duh, duh.shape, '\\n')\n",
    "    print(dzh_Wh, dzh_Wh.shape, '\\n')\n",
    "    print(dzh_bh, '\\n')\n",
    "    '''\n",
    "\n",
    "    # Calculating the gradients\n",
    "    grad_L_Wo = dLoss * dyHat * dzo_Wo\n",
    "    grad_L_bo = dLoss * dyHat * dzo_bo\n",
    "    grad_L_Wh = dLoss * dyHat * dzo_uh * duh * dzh_Wh\n",
    "    # grad_L_Wh = dLoss * dyHat * torch.matmul(dzo_uh, duh) * dzh_Wh\n",
    "    # grad_L_bh = dLoss * dyHat * dzo_uh * duh * dzh_bh\n",
    "    grad_L_bh = dLoss * dyHat * torch.matmul(dzo_uh, duh) * dzh_bh\n",
    "\n",
    "    return grad_L_Wo, grad_L_bo, grad_L_Wh, grad_L_bh"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Computing the Forward phase and Backward phase"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "x = torch.tensor([[1], [1]], dtype=torch.int32)\n",
    "\n",
    "# Forward phase\n",
    "n = Net(x)\n",
    "loss, yHat = n.forward_pass()\n",
    "\n",
    "# Backward phase\n",
    "grad_L_Wo, grad_L_bo, grad_L_Wh, grad_L_bh = n.backward_pass(yHat)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction =  0.9999963045120239\n",
      "Loss =  3.6954948e-06\n"
     ]
    }
   ],
   "source": [
    "print(\"Prediction = \", yHat.numpy().item())\n",
    "print(\"Loss = \", loss.numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dL/dWo = [[-1.4781952e-05]\n",
      " [-0.0000000e+00]] \n",
      "\n",
      "dL/dbo = -3.6954879760742188e-06 \n",
      "\n",
      "dL/dWh = [[-1.4781952e-05 -2.2172928e-05]\n",
      " [-0.0000000e+00 -0.0000000e+00]] \n",
      "\n",
      "dL/dbh = -1.4781951904296875e-05 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"dL/dWo = {} \\n\".format(grad_L_Wo.numpy()))\n",
    "print(\"dL/dbo = {} \\n\".format(grad_L_bo.numpy().item()))\n",
    "print(\"dL/dWh = {} \\n\".format(grad_L_Wh.numpy()))\n",
    "print(\"dL/dbh = {} \\n\".format(grad_L_bh.numpy().item()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# End of Notebook"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}